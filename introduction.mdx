---
title: Introduction
description: "Playground, Monitoring, Analytics & Evaluations for LLM Developers"
---

<img className="block dark:hidden" src="/images/shield.png" alt="Hero Light" />
<img className="hidden dark:block" src="/images/shield.png" alt="Hero Dark" />

## Overview

Murnitur AI provides a comprehensive platform for developers working with Large Language Models (LLMs). It features an interactive playground for experimentation, along with robust tools for monitoring, analytics, and evaluations to enhance the development and performance of LLM applications.

- **Security**: Secure Your AI Applications with [Murnitur Shield](/murnitur-shield/overview).
- **Observe**: Track, monitor, and debug LLM applications.
- **Evaluate**: Run automatic evaluations to detect hallucination, toxicity, and many other metrics.
- **Test**: Implement automated continuous integration (CI) tests for your application.
- **Manage Prompts**: Organize and version control prompts.
- **Curate Datasets**: Develop datasets for fine-tuning or evaluation purposes.
- **Analyze**: Engage experts for annotation and collecting human feedback.
- **Compare**: Evaluate and compare various LLM models within the playground.
